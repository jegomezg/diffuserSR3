{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import diffuserSR3.dataset as data \n",
    "import diffuserSR3.pipeline as Pipeline\n",
    "import diffuserSR3.unet2D as Unet\n",
    "import diffuserSR3.util as Utils\n",
    "import tqdm\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt={\"name\": \"Flair\",\n",
    "     \n",
    "     \"data\":{\n",
    "        \"train_dataroot\": \"/share/projects/ottopia/superstable/sr3/flair/data/train_64_512\",\n",
    "        \"test_dataroot\": \"/share/projects/ottopia/superstable/sr3/flair/data/test_64_512\",\n",
    "        \"l_resolution\": 64,\n",
    "        \"r_resolution\": 512,\n",
    "        \"use_shuffle\": True,\n",
    "        \"train_data_len\": -1,\n",
    "        \"test_data_len\": 50,\n",
    "        \n",
    "        },\n",
    "     \"model\":{\n",
    "         \"image_size\":512,\n",
    "         \"in_channels\":6,\n",
    "         \"out_channels\":3,\n",
    "         \"layers_per_block\":5,\n",
    "         \"block_out_channels\": (128, 128, 256, 256, 512, 512),\n",
    "         \"down_block_types\":(\n",
    "            \"DownBlock2D\",  # a regular ResNet downsampling block\n",
    "            \"DownBlock2D\",\n",
    "            \"DownBlock2D\",\n",
    "            \"DownBlock2D\",\n",
    "            \"AttnDownBlock2D\",  # a ResNet downsampling block with spatial self-attention\n",
    "            \"AttnDownBlock2D\",# Initialize accelerator and tensorboard logging\n",
    "            ),\n",
    "         \"up_block_types\":(\n",
    "            \"UpBlock2D\",  # a regular ResNet upsampling block\n",
    "            \"AttnUpBlock2D\",  # a ResNet upsampling block with spatial self-attention\n",
    "            \"AttnUpBlock2D\",\n",
    "            \"UpBlock2D\",\n",
    "            \"UpBlock2D\",\n",
    "            \"UpBlock2D\",\n",
    "            ),\n",
    "         \"scheduler\":{\n",
    "            \"type\":\"DDIM\",\n",
    "             \"num_train_timesteps\":1000,\n",
    "             \"num_test_timesteps\":100,\n",
    "             \"beta_start\":0.0001,\n",
    "             \"beta_end\":0.02,\n",
    "             \"beta_schedule\": \"linear\",\n",
    "             \"eta\": .0\n",
    "            },   \n",
    "         },\n",
    "     \n",
    "         \"trainning\":{\n",
    "            \"num_epochs\":100,\n",
    "            \"batch_size\": 2,\n",
    "            \"use_shuffle\": True,\n",
    "            \"num_workers\": 1\n",
    "         },\n",
    "         \"accelerator\":{\n",
    "            \"mixed_presition\":\"fp16\",\n",
    "            \"gradient_accumulation_steps\":1,\n",
    "            \n",
    "         }\n",
    "    }\n",
    "dataset = data.create_dataset(opt['data'],'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloadet = data.create_dataloader(dataset,opt['trainning'],\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=[]\n",
    "for i,(batch,name) in enumerate(dataloadet):\n",
    "    data1.append(batch)\n",
    "    if i>1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt['model']['in_channels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 512, 512])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Unet.crreate_unet2D(opt['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/home/e2109121/.conda/envs/superstable/lib/python3.11/site-packages/accelerate/accelerator.py:249: FutureWarning: `logging_dir` is deprecated and will be removed in version 0.18.0 of ðŸ¤— Accelerate. Use `project_dir` instead.\n",
      "  warnings.warn(\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjegomezg\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/share/mastoc/projects/ottopia/superstable/SRdiff/wandb/run-20230418_175451-lj3vywfp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jegomezg/example_project/runs/lj3vywfp' target=\"_blank\">zany-jazz-1</a></strong> to <a href='https://wandb.ai/jegomezg/example_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jegomezg/example_project' target=\"_blank\">https://wandb.ai/jegomezg/example_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jegomezg/example_project/runs/lj3vywfp' target=\"_blank\">https://wandb.ai/jegomezg/example_project/runs/lj3vywfp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize accelerator and tensorboard logging\n",
    "accelerator = Utils.create_accelerator(opt['accelerator'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare everything\n",
    "# There is no specific order to remember, you just need to unpack the\n",
    "# objects in the same order you gave them to the prepare method.\n",
    "model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, lr_scheduler\n",
    ")\n",
    "global_step = 0\n",
    "\n",
    "# Now you train the model\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(opt['num_epochs']):\n",
    "\n",
    "    progress_bar = tqdm(total=len(train_dataloader), disable=not accelerator.is_local_main_process)\n",
    "    progress_bar.set_description(f\"Epoch {epoch}\")\n",
    "    \n",
    "    for step, (batch,index) in enumerate(train_dataloader):\n",
    "\n",
    "\n",
    "        scheduler = Pipeline.create_SR3scheduler()       \n",
    "        noise = torch.randn(batch.shape).to(device)   \n",
    "        bs = batch.shape[0]            \n",
    "        timesteps = torch.randint(0, scheduler.config.num_train_timesteps, (bs,),device=device).long()  \n",
    "        noisy_images = scheduler.add_noise(data1[0],timesteps=timesteps,noise=noise)\n",
    "        \n",
    "        with accelerator.accumulate(model):\n",
    "            # Predict the noise residual\n",
    "            noise_pred = model(noisy_images, timesteps, return_dict=False)[0]\n",
    "            loss = F.mse_loss(noise_pred, noise)\n",
    "            accelerator.backward(loss)\n",
    "            accelerator.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "        logs = {\"loss\": loss.detach().item(), \"lr\": lr_scheduler.get_last_lr()[0], \"step\": global_step}\n",
    "        progress_bar.set_postfix(**logs)\n",
    "        accelerator.log(logs, step=global_step)\n",
    "        global_step += 1\n",
    "    # After each epoch you optionally sample some demo images with evaluate() and save the model\n",
    "    if accelerator.is_main_process:\n",
    "        \n",
    "        \n",
    "        pipeline = DDPMPipeline(unet=accelerator.unwrap_model(model), scheduler=noise_scheduler)\n",
    "        if (epoch + 1) % config.save_image_epochs == 0 or epoch == config.num_epochs - 1:\n",
    "\n",
    "            evaluate(config, epoch, pipeline)\n",
    "            if config.push_to_hub:\n",
    "                repo.push_to_hub(commit_message=f\"Epoch {epoch}\", blocking=True)\n",
    "            else:\n",
    "                pipeline.save_pretrained(config.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/home/e2109121/.conda/envs/superstable/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "usage: ipykernel_launcher.py [-h] [-c CONFIG] [-p {train,val}] [-gpu GPU_IDS]\n",
      "                             [-debug]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9008 --control=9006 --hb=9005 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"90aa1686-61de-4e4b-adee-f761a2d0a0cb\" --shell=9007 --transport=\"tcp\" --iopub=9009 --f=/share/home/e2109121/.local/share/jupyter/runtime/kernel-v2-25798872X7CTatTyibS.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/home/e2109121/.conda/envs/superstable/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3513: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import diffuserSR3.dataset as Data \n",
    "import diffuserSR3.pipeline as Pipeline\n",
    "import diffuserSR3.unet2D as Unet\n",
    "import diffuserSR3.util as Utils\n",
    "import diffuserSR3.logger as Logger\n",
    "\n",
    "from diffusers.optimization import get_cosine_schedule_with_warmup\n",
    "\n",
    "import logging\n",
    "import argparse\n",
    "\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-c', '--config', type=str, default='config.json',\n",
    "                        help='JSON file for configuration')\n",
    "    parser.add_argument('-p', '--phase', type=str, choices=['train', 'val'],\n",
    "                        help='Run either train(training) or val(generation)', default='train')\n",
    "    parser.add_argument('-gpu', '--gpu_ids', type=str, default=None)\n",
    "    parser.add_argument('-debug', '-d', action='store_true')\n",
    "\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    opt = Logger.parse(args)\n",
    "    # Convert to NoneDict, which return None for missing key.\n",
    "    opt = Logger.dict_to_nonedict(opt)\n",
    "    \n",
    "    Logger.setup_logger(None, opt['path']['log'], 'train', level=logging.INFO, screen=True)\n",
    "    Logger.setup_logger('val', opt['path']['log'], 'val', level=logging.INFO)\n",
    "\n",
    "    logger = logging.getLogger('base')\n",
    "    logger.info(Logger.dict2str(opt))\n",
    "    \n",
    "    # dataset\n",
    "    if opt['phase'] == 'train' and args.phase != 'val':\n",
    "        train_set = Data.create_dataset(opt['data'], opt['phase'])\n",
    "        train_loader = Data.create_dataloader(train_set, opt['data'], 'train')\n",
    "        val_set = Data.create_dataset(opt['data'], opt['phase'])\n",
    "        val_loader = Data.create_dataloader(val_set, opt['data'], 'test')\n",
    "    elif opt['phase'] == 'test':\n",
    "        val_set = Data.create_dataset(opt['data'], 'test')\n",
    "        val_loader = Data.create_dataloader(val_set, opt['data'], 'test')\n",
    "    logger.info('Initial Dataset Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "superstable",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
